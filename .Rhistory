pull(word)
library(rattle)
rattle()
library(rattle)
rattle()
df <- read.csv("UI_ISU.csv")
df$Iowa[20] <- 18
df$ISU[20] <- 17
df$margin <- abs(df$Iowa - df$ISU)
df$IowaWin <- df$Iowa > df$ISU
df$IowaWin <- as.factor(df$IowaWin)
df$IowaWin <- as.integer(df$IowaWin)
library(tidytext)
library(tidyverse)
df <- "I like dogs. I like cats."
library(tidytext)
library(tidyverse)
df <- "I like dogs. I like cats."
df %>% sentences
sentences
df %>% unnest_tokens(sentence)
df %>% unnest_tokens(sentence, token = "sentences")
unnest_tokens(sentence, "I like dogs. I like cats.",token = "sentences")
unnest_tokens(sentence, "I like dogs. I like cats.",token = "sentences")
unnest_tokens("I like dogs. I like cats.",token = "sentences")
df %>% as.data.frame()
df <- df %>% as.data.frame()
unnest_tokens(sentence, df,token = "sentences")
unnest_tokens(sentence, df ,token = "sentences")
unnest_tokens( df ,token = "sentences")
df %>% unnest_tokens(sentence, df$., token = "sentences")
df <- data.frame("text" = "I like cats. I like dogs. I hate humans.")
View(df)
df %>% unnest_tokens(sentence, "text", token = "sentences")
df %>% unnest_tokens(sentence, "text", token = "sentences") %>%
unnest_tokens(word, "sentence", token = "words")
df %>% unnest_tokens(sentence, "text", token = "sentences") %>%
unnest_tokens(word, "sentence", token = "words") %>%
count(word)
df %>% unnest_tokens(sentence, "text", token = "sentences") %>%
unnest_tokens(word, "sentence", token = "words") %>%
count(word)
df %>% unnest_tokens(sentence, "text", token = "sentences")
df %>% unnest_tokens(sentence, "text", token = "sentences") %>% view()
df <- data.frame("text" = c("I like dogs.","I like cats.","I hate turtles.","I like turtles."))
View(df)
df %>% unnest_tokens(sentence, "text", token = "sentences")
df %>% unnest_tokens(sentence, "text", token = "sentences") %>% view()
df %>% unnest_tokens(word, "text", token = "words")
df %>% unnest_tokens(word, "text", token = "word")
df %>% unnest_tokens(word, "text", token = "words")
df %>% unnest_tokens(word, "text")
df %>% unnest_tokens(word, "text")
df
df %>% unnest_tokens(word, "text")
df %>% unnest_tokens(word, text)
str(df)
df %>% as.character()
df$text <- df$text %>% as.character()
df %>% unnest_tokens(word, text)
df %>% unnest_tokens(word, text) %>% view()
df <- data.frame("text" = c("I like dogs.","I like cats.","I hate turtles.","I like turtles."), line = 1:4)
df$text <- df$text %>% as.character()
df %>% unnest_tokens(word, text) %>% view()
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word,line,n)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word,line,n) %>%
filter(tf_idf != 0)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0) %>%
arrange(line)
df %>%
unnest_tokens(word, text) %>%
count(line,word) %>%
group_by(line) %>%
top_n(n,n=2)
df %>%
unnest_tokens(word, text) %>%
count(line,word) %>%
arrange(line)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0) %>%
arrange(line)
df %>%
unnest_tokens(word, text) %>%
count(line,word) %>%
arrange(line)
.333/1.39
df <- data.frame("text" = c("I like dogs.",
"I like cats.",
"I like turtles.",
"I like penguins."), line = 1:4)
df$text <- df$text %>% as.character()
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(line, word, n)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0)
df %>%
unnest_tokens(word,text) %>%
count(line,word)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0)
df <- data.frame("text" = c("I like dogs.",
"I like cats.",
"I like turtles.",
"I like penguins.",
"I hate dogs",
"I hate cats",
"I hate turtles",
"I hate penguins"), line = 1:8)
df$text <- df$text %>% as.character()
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0) %>%
group_by(line) %>%
filter(tf_idf = max(tf_idf))
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0) %>%
group_by(line) %>%
filter(tf_idf == max(tf_idf))
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0) %>%
group_by(line)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0) %>%
group_by(line) %>%
arrange(line, tf_idf)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0) %>%
group_by(line) %>%
arrange(line, -tf_idf)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0) %>%
group_by(line) %>%
arrange(word)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
filter(tf_idf != 0) %>%
group_by(line) %>%
arrange(tf_idf)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
group_by(line) %>%
arrange(tf_idf)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
group_by(line) %>%
arrange(-tf_idf)
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
group_by(line)
df <- data.frame("character" = c("John","John","John","John","Mary","Mary","Mary","Mary"),
"text" = c("I like dogs.",
"I like cats.",
"I like turtles.",
"I like penguins.",
"I hate dogs",
"I hate cats",
"I hate turtles",
"I hate penguins"), line = 1:8)
df$text <- df$text %>% as.character()
df %>%
unnest_tokens(word, text) %>%
count(line, word) %>%
bind_tf_idf(word, line, n) %>%
group_by(line)
df %>%
unnest_tokens(word, text) %>%
count(character, word) %>%
bind_tf_idf(word, character, n) %>%
group_by(line)
df %>%
unnest_tokens(word, text) %>%
count(character, word) %>%
bind_tf_idf(word, character, n) %>%
group_by(character)
df %>%
unnest_tokens(word, text) %>%
count(character, word) %>%
bind_tf_idf(word, character, n) %>%
group_by(character) %>%
top_n(tf_idf, n = 1)
df %>% unnest_tokens(word,text) %>%
count(character, word)
df %>% unnest_tokens(word,text) %>%
count(character, word) %>%
top_n(n, n =1)
df %>% unnest_tokens(word,text) %>%
count(character, word) %>%
group_by(character) %>%
top_n(n, n =1)
(tf_idf, n = 1)
df %>%
unnest_tokens(word, text) %>%
count(character, word) %>%
bind_tf_idf(word, character, n) %>%
group_by(character) %>%
top_n(tf_idf, n = 1)
df %>% unnest_tokens(word,text) %>%
count(character, word) %>%
group_by(character) %>%
top_n(n, n =1)
library(rattle)
rattle()
library(rattle)
rattle()
library(caret)
library(tidyverse)
iris
model <- train(Species~.,
data = iris,
method = "rf",
trCOntrol = trainControl(method = "boot",
classProbs = TRUE,
summaryFunction = multiClassSummary))
model
multiClassSummary(model)
multiClassSummary(model$pred)
multiClassSummary(model$pred, model$results)
?multiClassSummary
model$pred
model$finalModel$predicted
model$finalModel$y
model$finalModel$obsLevels
multiClassSummary(iris,model$finalModel$obsLevels, model)
multiClassSummary(iris,model$finalModel$obsLevels, model)
model$finalModel
model$finalModel$confusion
confusionMatrix(model)
model
model <- train(Species~.,
data = iris,
method = "rf",
trCOntrol = trainControl(method = "boot",
classProbs = TRUE,
summaryFunction = multiClassSummary),
metric = "recall")
extractProb(model)
extractProb(model$finalModel)
predict(model, iris, type = "prob")
predict(model, iris, type = "prob") %>% cbind(iris$Species)
library(rattle)
rattle()
library(rattle)
rattle()
mtcars
df <- mtcars
df$efficient <- ifelse(df$mpg <20, 0,1)
df$efficient2 <- as.numeric(df$mpg < 20)
df$efficient
df$efficient2
df$efficient2 <- as.numeric(df$mpg >= 20)
df$efficient2
df$mpg
View(df)
df <- mtcars
df$efficient <- ifelse(df$mpg <20, 0,1)
df$efficient2 <- as.numeric(df$mpg >= 20)
str(df)
#Andrew Couch
rm(list = ls())
#1
raw_df <- read.csv("scary_movies.txt")
movie_df <- read.csv("scary_movies.txt", sep = "\t", stringsAsFactors = FALSE,
na.strings = c("", " ", "-"),
colClasses = c("integer","character","integer","integer","factor","character","numeric","numeric","integer","integer","character","factor","factor"))
movie_df$ReleaseDate <- as.Date(movie_df$ReleaseDate, "%B%d,%Y")
#2
levels(movie_df$Language)
levels(movie_df$Genre1)
movie_df[which(movie_df$Genre1 == "Acion"),"Genre1"] <- "Action"
levels(movie_df$Genre1)[which(levels(movie_df$Genre1) == "Acion")] <- "Action"
movie_df[which(movie_df$Genre1 == "Horrror"),"Genre1"] <- "Horror"
levels(movie_df$Genre1)[which(levels(movie_df$Genre1) == "Horrror")] <- "Horror"
levels(movie_df$Genre1)
unique(movie_df$Genre1)
#3
movie_df$Profit <- as.integer(movie_df$Revenue - movie_df$Budget)
movie_df$ReleaseYear <- format(movie_df$ReleaseDate, "%Y")
movie_df$Decade <- as.factor(paste(substr(movie_df$ReleaseYear,1,3),"0s",sep =""))
#4
movie_df$PopularityNorm <- 10*(movie_df$Popularity - min(movie_df$Popularity)) / (max(movie_df$Popularity) - min(movie_df$Popularity))
#5
missing_columns <- colSums(is.na(movie_df))
movie_df$BudgetMedian <- movie_df$Budget
movie_df$BudgetMedian[which(is.na(movie_df$BudgetMedian))] <- median(movie_df$Budget, na.rm = TRUE)
DecadeTable <- aggregate(movie_df$Budget, by  = list(movie_df$Decade), FUN = mean, na.rm = TRUE)
movie_df$BudgetSimilar <- movie_df$Budget
movie_df$BudgetSimilar[which(is.na(movie_df$BudgetSimilar))] <- DecadeTable[match(movie_df[which(is.na(movie_df$BudgetSimilar)),"Decade"], DecadeTable$Group.1),"x"]
library(tidyverse)
library(tidytext)
df <- read.csv("DemDebates.csv", colClasses = c("factor","factor","character"))
df <- df %>%
filter(!character %in% c("(Unknown)", "Announcer","Bash","Bridgewater","Burnett","Cooper","Davis","Diaz-Balart","Guthrie","Holt","Jose Diaz-Balart","Lacey","Lemon","Lester Holt", "Maddow","Muir","Protesters","Protestor","Ramos","Savannah Guthrie","Stephanopoulos","Tapper","Todd","Unknown"))
options(scipen = 999)
df %>%
unnest_tokens(trigram, "text", token = "ngrams", n = 3) %>%
count(character, trigram) %>%
bind_tf_idf(trigram, character,n) %>%
group_by(character) %>%
top_n(tf_idf, n = 5) %>%
mutate(rank = rank(tf_idf, ties.method = "random")) %>%
arrange(character, rank) %>%
filter(rank <=5) %>%
ggplot(aes(x = reorder_within(trigram, tf_idf, character),
y = tf_idf,
color = character,
fill = character)) +
geom_col() +
scale_x_reordered() +
facet_wrap(~character, scales = "free") +
coord_flip() +
theme(legend.position = "None")
df %>%
unnest_tokens(trigram, "text", token = "ngrams", n = 3) %>%
count(character, trigram) %>%
bind_tf_idf(trigram, character,n) %>%
group_by(character) %>%
top_n(tf_idf, n = 5) %>%
mutate(rank = rank(tf_idf, ties.method = "random")) %>%
arrange(character, rank) %>%
filter(rank <=5) %>%
ggplot(aes(x = reorder_within(trigram, tf_idf, character),
y = tf_idf,
color = character,
fill = character)) +
geom_col() +
scale_x_reordered() +
facet_wrap(~character, scales = "free") +
coord_flip() +
theme(legend.position = "None")
library(tidyverse)
library(tidytext)
df <- read.csv("DemDebates.csv", colClasses = c("factor","factor","character"))
df <- df %>%
filter(!character %in% c("(Unknown)", "Announcer","Bash","Bridgewater","Burnett","Cooper","Davis","Diaz-Balart","Guthrie","Holt","Jose Diaz-Balart","Lacey","Lemon","Lester Holt", "Maddow","Muir","Protesters","Protestor","Ramos","Savannah Guthrie","Stephanopoulos","Tapper","Todd","Unknown"))
options(scipen = 999)
devtools::install_github("ricardo-bion/ggradar",
dependencies = TRUE)
install.packages("digest")
devtools::install_github("ricardo-bion/ggradar",
dependencies = TRUE)
remove.packages("digest")
devtools::install_github("ricardo-bion/ggradar",
dependencies = TRUE)
#Andrew Couch
rm(list = ls())
library(jsonlite)
#1
yelp_df <- stream_in(file("madison_hotels.json"))
yelp_df$city <- as.factor(yelp_df$city)
yelp_df$state <- NULL
yelp_df$postal_code <- as.factor(yelp_df$postal_code)
yelp_df$date <- as.Date(yelp_df$date, "%Y-%m-%d")
#2
barplot(table(yelp_df$stars), data = yelp_df, col = "blue", xlab = "Stars", ylab = "Total Number of Reviews")
#3
total_hotels <- as.integer(length(unique(yelp_df$business_id)))
repeat_reviewers <- unique(yelp_df[which(duplicated(yelp_df$user_id) == TRUE),"user_id"])
#4
library(dplyr)
city_summary <- summarise(group_by(yelp_df, city),Total_Reviews = n(), Mean_Rating = mean(stars), Median_Rating = median(stars))
worst_city <- city_summary[which(min(city_summary$Mean_Rating) == city_summary$Mean_Rating),"city"]
setwd("~/R work/Debate-Sentiment-Analysis")
library(tidyverse)
library(tidytext)
df <- read.csv("DemDebate.csv")
setwd("~/R work/Debate-Sentiment-Analysis")
df <- read.csv("DemDebates.csv")
df %>% str()
df$text <- as.character(df$text)
df %>% unnest_tokens(word, "text")
df %>%
unnest_tokens(word, "text") %>%
count(word, word)
df %>%
unnest_tokens(word, "text") %>%
count(word, word) %>%
arrrange(-n)
df %>%
unnest_tokens(word, "text") %>%
count(word, word) %>%
arrange(-n)
df %>%
unnest_tokens(word, "text") %>%
count(word, word) %>%
arrange(-n) %>%
mutate(rank = rank(n))
df %>%
unnest_tokens(word, "text") %>%
count(word, word) %>%
arrange(-n) %>%
mutate(rank = rank(-n))
df %>%
unnest_tokens(word, "text") %>%
count(word, word) %>%
arrange(-n) %>%
mutate(rank = rank(-n)) %>%
mutate(n = log(n), rank = log(rank))
df %>%
unnest_tokens(word, "text") %>%
count(word, word) %>%
arrange(-n) %>%
mutate(rank = rank(-n)) %>%
mutate(n = log(n), rank = log(rank)) %>%
ggplot(aes(x = rank, y = n))
df %>%
unnest_tokens(word, "text") %>%
count(word, word) %>%
arrange(-n) %>%
mutate(rank = rank(-n)) %>%
mutate(n = log(n), rank = log(rank)) %>%
ggplot(aes(x = rank, y = n)) + geom_point()
df %>%
unnest_tokens(word, "text") %>%
count(word, word) %>%
arrange(-n) %>%
mutate(rank = rank(-n)) %>%
mutate(n = log(n), rank = log(rank)) %>%
ggplot(aes(x = rank, y = n)) + geom_point() + geom_abline(slope = -1)
df %>%
unnest_tokens(word, "text") %>%
count(word, word) %>%
arrange(-n) %>%
mutate(rank = rank(-n)) %>%
mutate(n = log(n), rank = log(rank)) %>%
ggplot(aes(x = rank, y = n)) + geom_point() + geom_smooth(se = FALSE, method = "lm")
df %>%
unnest_tokens(word, "text") %>%
count(word, word) %>%
arrange(-n) %>%
mutate(rank = rank(-n)) %>%
mutate("logged freq" = log(n), "logged rank" = log(rank)) %>%
ggplot(aes(x = "logged freq", y = "logged rank")) + geom_point() + geom_smooth(se = FALSE, method = "lm")
df %>%
unnest_tokens(word, "text") %>%
count(word, word) %>%
arrange(-n) %>%
mutate(rank = rank(-n)) %>%
mutate(logged_freq = log(n), logged_rank = log(rank)) %>%
ggplot(aes(x = logged_freq, y = logged_rank)) + geom_point() + geom_smooth(se = FALSE, method = "lm")
df %>%
unnest_tokens(word, "text") %>%
count(word, word) %>%
arrange(-n) %>%
mutate(rank = rank(-n)) %>%
mutate(logged_freq = log(n), logged_rank = log(rank)) %>%
ggplot(aes(x = logged_freq, y = logged_rank)) + geom_point() + geom_smooth(se = FALSE, method = "lm")  + ggtitle("Zipfs Law")
group_by(iris, Species)
